{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "#将训练的mnist训练数据板块转成csv形式\n",
    "def load_mnist1(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels.idx1-ubyte'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images.idx3-ubyte'\n",
    "                               % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#将测试的mnist的测试数据板块转成csv形式\n",
    "def load_mnist2(path, kind='t10k'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels.idx1-ubyte'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images.idx3-ubyte'\n",
    "                               % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "X_train,y_train = load_mnist1('C:\\\\Users\\\\韦祖垚\\\\Desktop\\\\模式识别大作业韦祖垚\\\\data')\n",
    "np.savetxt('data\\\\train_img.csv', X_train,\n",
    "           fmt='%i', delimiter=',')        #train_img是训练的数据的图像的矩阵形式，一共784列\n",
    "np.savetxt('data\\\\train_labels.csv', y_train,\n",
    "           fmt='%i', delimiter=',')        #train_labels是训练的数据一般表示方法(0-9)，一列\n",
    "\n",
    "X_test,y_test=load_mnist2('C:\\\\Users\\\\韦祖垚\\\\Desktop\\\\模式识别大作业韦祖垚\\\\data')\n",
    "np.savetxt('data\\\\test_img.csv', X_test,\n",
    "           fmt='%i', delimiter=',')        #测试集的矩阵形式\n",
    "np.savetxt('data\\\\test_labels.csv', y_test,\n",
    "           fmt='%i', delimiter=',')        #测试集的数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "def all_csv1(file_PATH = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data',save_file=\"测试数据整合.csv\"):\n",
    "    df_list = [] #创建新列表用来存储提取出来的列表\n",
    "    df = pd.read_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\test_labels.csv',header=None)# 读取CSV文件数据\n",
    "    df.columns = ['labels']\n",
    "    data = df.iloc[:,:]# 选取文件中某行某列数据\n",
    "    df_list.append(data)# 将选取的数据添加到列表\n",
    "    df = pd.read_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\test_img.csv',header=None)\n",
    "    df.columns = [x for x in range (1,785)] # 添加自定义的columns的名字\n",
    "    data = df.iloc[:,:]\n",
    "    df_list.append(data)\n",
    "    df2 = pd.concat(df_list,axis=1)#将列表数据按列合并，axis=1表示按列整合\n",
    "    open(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\测试数据整合.csv', 'wb')\n",
    "    df2.to_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\测试数据整合.csv',index=False)#将整合好的数据输入到新建的csv文件中\n",
    "\n",
    "def all_csv2(file_PATH = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data',save_file=\"训练数据整合.csv\"):\n",
    "    df_list = []\n",
    "    df = pd.read_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\train_labels.csv',header=None)\n",
    "    df.columns = ['labels']\n",
    "    data = df.iloc[:,:]\n",
    "    df_list.append(data)\n",
    "    df = pd.read_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\train_img.csv',header=None)\n",
    "    df.columns = [x for x in range (1,785)]\n",
    "    data = df.iloc[:,:]\n",
    "    df_list.append(data)\n",
    "    df2 = pd.concat(df_list,axis=1)\n",
    "    open(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\训练数据整合.csv', 'wb')\n",
    "    df2.to_csv(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\训练数据整合.csv',index=False)\n",
    "\n",
    "all_csv1(file_PATH = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data',save_file=\"测试数据整合.csv\")\n",
    "all_csv2(file_PATH = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data',save_file=\"训练数据整合.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784']\n",
      "训练集大小47951，测试集大小12049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 143853/143853 [11:15<00:00, 212.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型识别正确率： 0.9114449331894763\n",
      "数字 0 的准确率: 0.9114449331894763\n",
      "数字 0 的精确率: 0.9526916802610114\n",
      "数字 0 的召回率: 0.5365181442351861\n",
      "数字 1 的准确率: 0.9114449331894763\n",
      "数字 1 的精确率: 0.9249823071479123\n",
      "数字 1 的召回率: 0.576278659611993\n",
      "数字 2 的准确率: 0.9114449331894763\n",
      "数字 2 的精确率: 0.933277027027027\n",
      "数字 2 的召回率: 0.5279503105590062\n",
      "数字 3 的准确率: 0.9114449331894763\n",
      "数字 3 的精确率: 0.8775981524249422\n",
      "数字 3 的召回率: 0.556640625\n",
      "数字 4 的准确率: 0.9114449331894763\n",
      "数字 4 的精确率: 0.9465290806754222\n",
      "数字 4 的召回率: 0.49975235264982665\n",
      "数字 5 的准确率: 0.9114449331894763\n",
      "数字 5 的精确率: 0.9323394495412844\n",
      "数字 5 的召回率: 0.4464579901153213\n",
      "数字 6 的准确率: 0.9114449331894763\n",
      "数字 6 的精确率: 0.9433198380566802\n",
      "数字 6 的召回率: 0.5388529139685476\n",
      "数字 7 的准确率: 0.9114449331894763\n",
      "数字 7 的精确率: 0.9677980852915579\n",
      "数字 7 的召回率: 0.5191409897292251\n",
      "数字 8 的准确率: 0.9114449331894763\n",
      "数字 8 的精确率: 0.8819672131147541\n",
      "数字 8 的召回率: 0.5382691345672836\n",
      "数字 9 的准确率: 0.9114449331894763\n",
      "数字 9 的精确率: 0.7848375451263538\n",
      "数字 9 的召回率: 0.5856681034482759\n"
     ]
    }
   ],
   "source": [
    "from NeuralNetwork import NeuralNetwork\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "def train():\n",
    "    file_name = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data'\t# 数据集为60000张带标签的28x28手写数字图像\n",
    "    y = []\n",
    "    x = []\n",
    "    y_t = []\n",
    "    x_t = []\n",
    "    with open(r\"C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\训练数据整合.csv\", 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header_row = next(reader)#遍历csv文件的每一行\n",
    "        print(header_row)\n",
    "        for row in reader:\n",
    "            if np.random.random() < 0.8:\t# 大约80%的数据用于训练\n",
    "                y.append(int(row[0]))#第一列为待识别对象的正确结果，将正确结果添加到y列表中\n",
    "                x.append(list(map(int, row[1:])))#第1位开始为图片转化成的矩阵，将矩阵添加到x列表中\n",
    "            else:#剩余的图片正确结果以及矩阵分别添加到y_t和x_t列表中用来测试\n",
    "                y_t.append(int(row[0]))\n",
    "                x_t.append(list(map(int, row[1:])))\n",
    "    len_train = len(y)\n",
    "    len_test = len(y_t)\n",
    "    print('训练集大小%d，测试集大小%d' % (len_train, len_test))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    nn = NeuralNetwork([784, 784, 10])\t# 神经网络各层神经元个数\n",
    "    nn.fit(x, y)\n",
    "    file = open(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\NN.txt', 'wb')\n",
    "    pickle.dump(nn, file)#将nn文件转换为python可以识别的数据对象\n",
    "    count = 0\n",
    "    for i in range(len_test):\n",
    "        p, _ = nn.predict(x_t[i])#将预测结果赋给p\n",
    "        if p == y_t[i]:\n",
    "            count += 1#如果预测结果和正确结果一样，count加一\n",
    "    print('模型识别正确率：', count/len_test)\n",
    "\n",
    "    for i in range(10):#遍历0~9十个数字\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        TN = 0\n",
    "        for j in range(len_test):#遍历测试集所有行\n",
    "            p, _ = nn.predict(x_t[j])\n",
    "            if (p == y_t[j] and p==i):\n",
    "                TP+=1\n",
    "            elif(p == y_t[j] and p!=i):\n",
    "                TN+=1\n",
    "            elif(p!=y_t[j] and p==i):\n",
    "                FP+=1\n",
    "            elif(p!=y_t[j] and p!=i):\n",
    "                FN+=1\n",
    "        print('数字',i,'的准确率:',(TP+TN)/(TP+FP+FN+TN))\n",
    "        print('数字',i,'的精确率:',(TP) / (TP + FP ))\n",
    "        print('数字',i,'的召回率:',(TP) / (TP + FN))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mini_test():\t# 小型测试，验证神经网络能正常运行\n",
    "    x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "    y = [0, 1, 2, 3]\n",
    "    nn = NeuralNetwork([2, 4, 16, 4])\n",
    "    nn.fit(x, y, epochs=10000)\n",
    "    for i in x:\n",
    "        print(nn.predict(i))\n",
    "\n",
    "\n",
    "# mini_test()\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_csv.reader object at 0x0000015B1CF032E8>\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '84', '185', '159', '151', '60', '36', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '222', '254', '254', '254', '254', '241', '198', '198', '198', '198', '198', '198', '198', '198', '170', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '67', '114', '72', '114', '163', '227', '254', '225', '254', '254', '254', '250', '229', '254', '254', '140', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '17', '66', '14', '67', '67', '67', '59', '21', '236', '254', '106', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '83', '253', '209', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '22', '233', '255', '83', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '129', '254', '238', '44', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '59', '249', '254', '62', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '187', '5', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '9', '205', '248', '58', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '126', '254', '182', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '75', '251', '240', '57', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '19', '221', '254', '166', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '203', '254', '219', '35', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '38', '254', '254', '77', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '31', '224', '254', '115', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '133', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '61', '242', '254', '254', '52', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '254', '219', '40', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '121', '254', '207', '18', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def diplay_test():\t# 读取测试集，预测，画图\n",
    "    file_name = r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\test_img.csv'\n",
    "    file = open(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\data\\\\NN.txt', 'rb')\n",
    "    nn = pickle.load(file)\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header_row = next(reader)\n",
    "        print(reader)\n",
    "        print(header_row)\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            i += 1\n",
    "            img = np.array(row, dtype=np.uint8)\n",
    "            img = img.reshape(28, 28)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            pre, lst = nn.predict(row)\n",
    "            plt.title(str(pre), fontsize=24)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(r'C:\\Users\\韦祖垚\\Desktop\\模式识别大作业韦祖垚\\\\img\\\\img' + str(i) + '.png')\n",
    "\n",
    "\n",
    "diplay_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
